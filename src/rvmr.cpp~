/**
 * @file rvmr.cpp
 * @author _____
 *
 * Implementation of the Relevance Vector Machine.
 *
 * mlpack is free software; you may redistribute it and/or modify it under the
 * terms of the 3-clause BSD license.  You should have received a copy of the
 * 3-clause BSD license along with mlpack.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#include "rvmr.hpp"

using namespace mlpack;


RVMR::RVMR(const bool fitIntercept,
	   const bool normalize) :
  fitIntercept(fitIntercept),
  normalize(normalize){

  this->kernelFunction = NULL;
  
  std::cout << "RVMR(fitIntercept="
  	    << this->fitIntercept
  	    << ", normalize="
  	    << this->normalize
  	    << ")"
  	    << std::endl;
  }

RVMR::RVMR(double (*kernelFunction)(arma::colvec&, arma::colvec&, double),
	   const bool fitIntercept,
	   const bool normalize,
	   double gamma) :
  kernelFunction(kernelFunction),
  fitIntercept(fitIntercept),
  normalize(normalize),
  gamma(gamma){
  
  std::cout << "RVMR_kernel(fitIntercept="
	    << this->fitIntercept
	    << ", normalize="
	    << this->normalize
	    << ")"
	    << std::endl;
  }


template<typename KernelType>
RVMR::RVMR(const kernel = KernelType(),
	   const bool fitIntercept = true,
	   const bool normalize = false) :
  kernel(kernel),
  fitIntercept(fitIntercept),
  normalize(normalize) {

    std::cout << "RVMR_kernel_mlpack(fitIntercept="
	      << this->fitIntercept
	      << ", normalize="
	      << this->normalize
	      << ")"
	      << std::endl;
  }


void RVMR::Train(const arma::mat& data,
		 const arma::rowvec& responses,
		 const bool rowMajor){

  arma::mat phi;
  arma::rowvec t;

  // Manage the kernel
  // We must keep the original training data for future predictions.
  this->phi = data;
  applyKernel(data, data, phi, this->kernel);
  
  //Preprocess the data. Center and normalize.
  preprocess_data(phi,
		  responses,
		  this->fitIntercept,
		  this->normalize,
		  phi,
		  t,
		  this->data_offset,
		  this->data_scale,
		  this->responses_offset);
 
  // else
  //   {
  //     //Preprocess the data. Center and normalize.
  //     preprocess_data(data,
  // 		      responses,
  // 		      this->fitIntercept,
  // 		      this->normalize,
  // 		      phi,
  // 		      t,
  // 		      this->data_offset,
  // 		      this->data_scale,
  // 		      this->responses_offset);
  //   }

  unsigned short p = phi.n_rows, n = phi.n_cols;
  // Initialize the hyperparameters and
  // begin with an infinitely broad prior.
  this->alpha_threshold = 1e4;   
  this->alpha = arma::ones<arma::rowvec>(p)*1e-6;
  this->beta =  1 / (arma::var(t) * 0.1);

  // Loop variables.
  double tol = 1e-5; 
  double L = 1.0;
  double crit = 1.0;
  unsigned short nIterMax = 50;
  unsigned short i = 0;
  unsigned short ind_act;

  arma::rowvec gammai = arma::zeros<arma::rowvec>(p);
  arma::mat matA;
  arma::rowvec temp(n);
  arma::mat subPhi;
  // Initiaze a vector of all the indices from the first
  // to the last point.
  arma::uvec allCols(n);
  for (size_t i=0; i < n; i++) {allCols[i] = i;}
  
  while ((crit > tol) && (i < nIterMax))
    {
      crit = -L;
      this->activeSet = find(this->alpha < this->alpha_threshold);
      // Prune out the inactive basis function. This procedure speeds up
      // the algorithm.
      subPhi = phi.submat(this->activeSet, allCols);

      // Compute the posterior statistics.
      matA = diagmat(this->alpha.elem(this->activeSet));
      this->matCovariance = inv(matA
				+ (subPhi
				   * subPhi.t())
				* this->beta);

      this->omega = (this->matCovariance
		     * subPhi
		     * t.t())
	* this->beta;
      
      // Update the alpha_i.
      for (size_t k=0; k<this->activeSet.size(); k++)
	{
	  ind_act = this->activeSet[k];
	  gammai[ind_act] = 1-this->matCovariance(k,k) *
	    this->alpha[ind_act];

	  this->alpha[ind_act] = gammai[ind_act]
	    / (this->omega[k] * this->omega[k]);
	}
      
      // Update beta.
      temp = t -  this->omega.t() * subPhi;
      this->beta = (n - sum(gammai.elem(this->activeSet))) / dot(temp, temp);
      
      // Comptute the stopping criterion.
      L = norm(this->omega);
      crit = abs(crit + L) / L;
      i++;
    }
}

void RVMR::Predict(const arma::mat& points,
		   arma::rowvec& predictions) const
{
  arma::mat X;
  // Manage the kernel.
  if (this->kernelFunction != NULL)
    gramMatrix(this->phi, points, X, this->kernelFunction, this->gamma);

  else
    X = points;

  arma::uvec allCols(X.n_cols);
  for (size_t i=0; i < X.n_cols; i++) {allCols[i] = i;}

  // Center and normalize the points before applying the model.
  X.each_col() -= this->data_offset;
  X.each_col() /= this->data_scale;
  predictions = this->omega.t() * X.submat(this->activeSet, allCols)
                + this->responses_offset;
}

void RVMR::Predict(const arma::mat& points,
		   arma::rowvec& predictions,
		   arma::rowvec& std) const
{
  arma::mat X;
  // Manage the kernel.
  if (this->kernelFunction != NULL)
    aplyKernel(this->phi, points, X, kernel);
  
  else
    X = points;
  
  arma::uvec allCols(X.n_cols);
  for (size_t i=0; i < X.n_cols; i++) {allCols[i] = i;}
  
  // Center and normalize the points before applying the model.
  X.each_col() -= this->data_offset;
  X.each_col() /= this->data_scale;
  predictions = this->omega.t() * X.submat(this->activeSet, allCols)
                + this->responses_offset;

  // Comptute the standard deviations
  arma::mat O(X.n_cols, X.n_cols);
  O = X.submat(this->activeSet, allCols).t()
    * this->matCovariance
    * X.submat(this->activeSet, allCols);
  std = sqrt(diagvec(1/this->beta + O).t());
}


float RVMR::Rmse(const arma::mat& data,
		 const arma::rowvec& responses) const
{
  arma::rowvec predictions;
  this->Predict(data, predictions);
  return sqrt(
	      mean(
		  square(responses - predictions)));
}



arma::vec RVMR::getCoefs() const
{
  // Get the size of the solution with the offset.
  arma::colvec coefs = arma::zeros<arma::colvec>(this->data_offset.size());
  // omega[i] = 0 for the inactive basis functions
  for (size_t i=0; i < this->activeSet.size(); i++)
    {
      coefs[this->activeSet[i]] = this->omega[i];
    }
  return coefs;
}

double RVMR::getBeta() const {return this->beta;}

arma::uvec RVMR::getActiveSet() const {return this->activeSet;}



void RVMR::applyKernel(const arma::mat& X,
		       const arma::mat& Y,
		       arma::mat& gramMatrix
		       KernelType kernel) {
  unsigned int n1 = X.n_cols;
  unsigned int n2 = Y.n_cols;
  unsigned int p = X.n_rows;
  
  // Check if the dimensions are consistent.
  if (p != Y.n_rows)
    {
      std::cout << "error gramm" << std::endl;
      throw std::invalid_argument("Number of features not consistent");
    }
  
  gramMatrix = zeros<mat>(X.n_cols, Y.n_cols);
  colvec xi = zeros<colvec>(p);
  colvec yj = zeros<colvec>(p);
  for (size_t i=0; i < X.n_cols; i++)
    {
      xi = X.col(i);
      for (size_t j=0; j < Y.n_cols; j++)
	{
	  yj = Y.col(j);
	  gramMatrix(i,j) = kernel.Evaluate(xi, yj);
	}
    }
}

